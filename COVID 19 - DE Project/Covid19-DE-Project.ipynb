{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40bd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries:\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AWS credentials and configuration:\n",
    "AWS_ACCESS_KEY = \"YOUR_ACCESS_KEY\"\n",
    "AWS_SECRET_KEY = \"YOUR_SECRET_KEY\"\n",
    "AWS_REGION = \"eu-west-2\"\n",
    "SCHEMA_NAME = \"covid19_db\"\n",
    "S3_STAGING_DIR = \"s3://nehal-dev-test-bucket/output6/\"\n",
    "S3_BUCKET_NAME = \"nehal-dev-test-bucket\"\n",
    "S3_OUTPUT_DIRECTORY = \"output6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Athena client:\n",
    "athena_client = boto3.client('athena',\n",
    "                    region_name=AWS_REGION,\n",
    "                    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "                    aws_secret_access_key=AWS_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0ddf1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to download and load query results into a DataFrame\n",
    "# This function uses the boto3 library to download the query results from S3 and load them into a DataFrame using pandas.\n",
    "Dict = {}\n",
    "def download_and_load_query_results(\n",
    "    client:boto3.client, query_response: Dict\n",
    "):\n",
    "    while True:\n",
    "        try:                \n",
    "            # This function only loads the first 1000 rows\n",
    "            client.get_query_results(\n",
    "                QueryExecutionId = query_response[\"QueryExecutionId\"]\n",
    "            )\n",
    "            break\n",
    "        except Exception as err:\n",
    "            if \"not yet finished\" in str(err):\n",
    "                time.sleep(0.001)\n",
    "            else:\n",
    "                raise err\n",
    "\n",
    "    temp_file_location: str=\"athena_query_results.csv\"\n",
    "\n",
    "    s3_client = boto3.client(\"s3\",\n",
    "                region_name=AWS_REGION,\n",
    "                aws_access_key_id=AWS_ACCESS_KEY,\n",
    "                aws_secret_access_key=AWS_SECRET_KEY )\n",
    "\n",
    "    s3_client.download_file(\n",
    "        S3_BUCKET_NAME,\n",
    "        f\"{S3_OUTPUT_DIRECTORY}/{query_response['QueryExecutionId']}.csv\",\n",
    "        temp_file_location,\n",
    "    )\n",
    "    return pd.read_csv(temp_file_location)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce978950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Athena queries and retrieve the results:\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString = \"SELECT * FROM enigma_jhud\",\n",
    "    QueryExecutionContext={'Database': SCHEMA_NAME},\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': S3_STAGING_DIR,\n",
    "        'EncryptionConfiguration' : {\"EncryptionOption\" : \"SSE_S3\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enigma_jhud = download_and_load_query_results(athena_client, response)\n",
    "enigma_jhud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f35298",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = athena_client.start_query_execution(\n",
    "    QueryString = \"SELECT * FROM nytimes_data_in_usa_us_statesus_states\",\n",
    "    QueryExecutionContext={'Database': SCHEMA_NAME},\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': S3_STAGING_DIR,\n",
    "        'EncryptionConfiguration' : {\"EncryptionOption\" : \"SSE_S3\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes_data_in_usa_us_states = download_and_load_query_results(athena_client, response)\n",
    "nytimes_data_in_usa_us_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = athena_client.start_query_execution(\n",
    "    QueryString = \"SELECT * FROM rearc_covid_19_testing_data_states_daily\",\n",
    "    QueryExecutionContext={'Database': SCHEMA_NAME},\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': S3_STAGING_DIR,\n",
    "        'EncryptionConfiguration' : {\"EncryptionOption\" : \"SSE_S3\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa03701",
   "metadata": {},
   "outputs": [],
   "source": [
    "rearc_covid_19_testing_data_states_daily = download_and_load_query_results(athena_client, response)\n",
    "rearc_covid_19_testing_data_states_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = athena_client.start_query_execution(\n",
    "    QueryString = \"SELECT * FROM rearc_usa_hospital_beds\",\n",
    "    QueryExecutionContext={'Database': SCHEMA_NAME},\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': S3_STAGING_DIR,\n",
    "        'EncryptionConfiguration' : {\"EncryptionOption\" : \"SSE_S3\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rearc_usa_hospital_beds = download_and_load_query_results(athena_client, response)\n",
    "rearc_usa_hospital_beds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = athena_client.start_query_execution(\n",
    "    QueryString = \"SELECT * FROM nytimes_data_in_usa_us_county\",\n",
    "    QueryExecutionContext={'Database': SCHEMA_NAME},\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': S3_STAGING_DIR,\n",
    "        'EncryptionConfiguration' : {\"EncryptionOption\" : \"SSE_S3\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes_data_in_usa_us_county = download_and_load_query_results(athena_client, response)\n",
    "nytimes_data_in_usa_us_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ce32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data processing and merge operations:\n",
    "factCovid_1 = enigma_jhud[['fips','province_state','country_region','confirmed','deaths','recovered','active']]\n",
    "factCovid_2 = rearc_covid_19_testing_data_states_daily[['fips','date','positive','negative','hospitalizedcurrently','hospitalized','hospitalizeddischarged']]\n",
    "factCovid = pd.merge(factCovid_1, factCovid_2, on='fips', how='inner')\n",
    "factCovid.head()\n",
    "\n",
    "dimRegion_1 = enigma_jhud[['fips','province_state','country_region','latitude','longitude']]\n",
    "dimRegion_2 = nytimes_data_in_usa_us_county[['fips','county','state']]\n",
    "dimRegion = pd.merge(dimRegion_1, dimRegion_2, on='fips', how='inner')\n",
    "dimRegion.head()\n",
    "\n",
    "dimHospital = rearc_usa_hospital_beds[['fips','state_name','latitude','longtitude','hq_address','hospital_name','hospital_type','hq_city','hq_state']]\n",
    "dimHospital.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns from the DataFrame rearc_covid_19_testing_data_states_daily and create a new DataFrame dimDate:\n",
    "dimDate = rearc_covid_19_testing_data_states_daily[['fips','date']]\n",
    "\n",
    "# Convert the 'date' column to datetime format:\n",
    "dimDate['date'] = pd.to_datetime(dimDate['date'], format='%Y%m%d')\n",
    "\n",
    "# Extract year, month, and day of the week from the 'date' column and add them as new columns:\n",
    "dimDate['year'] = dimDate['date'].dt.year\n",
    "dimDate['month'] = dimDate['date'].dt.month\n",
    "dimDate['day_of_week'] = dimDate['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimDate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factCovid.to_csv(r'D:\\1.IT PROJECT WORK\\4.Data Engineer\\Darsheel Parmar\\COVID 19 - Build End to End Data Engineering Project\\factCovid.csv')\n",
    "# dimRegion.to_csv(r'D:\\1.IT PROJECT WORK\\4.Data Engineer\\Darsheel Parmar\\COVID 19 - Build End to End Data Engineering Project\\dimRegion.csv')\n",
    "# dimHospital.to_csv(r'D:\\1.IT PROJECT WORK\\4.Data Engineer\\Darsheel Parmar\\COVID 19 - Build End to End Data Engineering Project\\dimHospital.csv')\n",
    "# dimDate.to_csv(r'D:\\1.IT PROJECT WORK\\4.Data Engineer\\Darsheel Parmar\\COVID 19 - Build End to End Data Engineering Project\\dimDate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5708ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 resource object:\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "# Define the S3 bucket name:\n",
    "bucket = 'nehal-covid-de-project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and upload DataFrames to S3 as CSV files:\n",
    "csv_buffer = StringIO()\n",
    "factCovid.to_csv(csv_buffer)\n",
    "s3_resource.Object(bucket, 'output/factCovid.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "dimRegion.to_csv(csv_buffer)\n",
    "s3_resource.Object(bucket, 'output/dimRegion.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "dimHospital.to_csv(csv_buffer)\n",
    "s3_resource.Object(bucket, 'output/dimHospital.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "dimDate.to_csv(csv_buffer)\n",
    "s3_resource.Object(bucket, 'output/dimDate.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print SQL schemas for DataFrames:\n",
    "factCovidsql = pd.io.sql.get_schema(factCovid.reset_index(), 'factCovid')\n",
    "print(''.join(factCovidsql))\n",
    "\n",
    "dimHospitalsql = pd.io.sql.get_schema(dimHospital.reset_index(), 'dimHospital')\n",
    "print(''.join(dimHospitalsql))\n",
    "\n",
    "dimDatesql = pd.io.sql.get_schema(dimDate.reset_index(), 'dimDate')\n",
    "print(''.join(dimDatesql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864baa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the redshift-connector library:\n",
    "pip install redshift-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redshift_connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Amazon Redshift:\n",
    "conn = redshift_connector.connect(\n",
    "    host='my-first-redshift.cvxs7hla7yh8.eu-west-2.redshift.amazonaws.com',\n",
    "    database='myfirstdb',\n",
    "    user='user',\n",
    "    password=\"Password\"\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor= redshift_connector.Cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11dff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute SQL queries to create tables into Redshift:\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE \"factCovid\" (\n",
    "\"index\" INTEGER,\n",
    "  \"fips\" REAL,\n",
    "  \"province_state\" TEXT,\n",
    "  \"country_region\" TEXT,\n",
    "  \"confirmed\" REAL,\n",
    "  \"deaths\" REAL,\n",
    "  \"recovered\" REAL,\n",
    "  \"active\" REAL,\n",
    "  \"date\" INTEGER,\n",
    "  \"positive\" REAL,\n",
    "  \"negative\" REAL,\n",
    "  \"hospitalizedcurrently\" REAL,\n",
    "  \"hospitalized\" REAL,\n",
    "  \"hospitalizeddischarged\" REAL\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE \"dimHospital\" (\n",
    "\"index\" INTEGER,\n",
    "  \"fips\" REAL,\n",
    "  \"state_name\" TEXT,\n",
    "  \"latitude\" REAL,\n",
    "  \"longtitude\" REAL,\n",
    "  \"hq_address\" TEXT,\n",
    "  \"hospital_name\" TEXT,\n",
    "  \"hospital_type\" TEXT,\n",
    "  \"hq_city\" TEXT,\n",
    "  \"hq_state\" TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE \"dimDate\" (\n",
    "\"index\" INTEGER,\n",
    "  \"fips\" INTEGER,\n",
    "  \"date\" TIMESTAMP,\n",
    "  \"year\" INTEGER,\n",
    "  \"month\" INTEGER,\n",
    "  \"day_of_week\" INTEGER\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute SQL queries to copy data from S3 into Redshift:\n",
    "cursor.execute(\"\"\"\n",
    "    copy dimDate from 's3://nehal-covid-de-project/output/dimDate.csv'\n",
    "    credentials 'aws_iam_role=arn:aws:iam::127656700581:role/Redshift-S3-access'\n",
    "    delimiter ','\n",
    "    region 'eu-west-2'\n",
    "    IGNOREHEADER 1\n",
    "    \"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    copy dimHospital from 's3://nehal-covid-de-project/output/dimHospital.csv'\n",
    "    credentials 'aws_iam_role=arn:aws:iam::127658009581:role/Redshift-S3-access'\n",
    "    delimiter ','\n",
    "    region 'eu-west-2'\n",
    "    IGNOREHEADER 1\n",
    "    \"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    copy factCovid from 's3://nehal-covid-de-project/output/factCovid.csv'\n",
    "    credentials 'aws_iam_role=arn:aws:iam::127654009581:role/Redshift-S3-access'\n",
    "    delimiter ','\n",
    "    region 'eu-west-2'\n",
    "    IGNOREHEADER 1\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
